{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EMAIL PROCESSING ===\n",
      "{\n",
      "  \"conversation_id\": \"3022f0e749f4\",\n",
      "  \"classification\": {\n",
      "    \"format\": \"Email\",\n",
      "    \"intent\": \"Complaint\"\n",
      "  },\n",
      "  \"result\": {\n",
      "    \"sender\": \"customer@example.com\",\n",
      "    \"intent\": \"Complaint\",\n",
      "    \"urgency\": \"Urgent\",\n",
      "    \"topics\": [\n",
      "      \"Laptop\",\n",
      "      \"Screen Flickering\",\n",
      "      \"Product Defect\"\n",
      "    ],\n",
      "    \"summary\": \"Customer is complaining about a laptop screen flickering within 3 days of purchase and wants urgent resolution.\"\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "=== JSON PROCESSING ===\n",
      "{\n",
      "  \"conversation_id\": \"bba78d1def59\",\n",
      "  \"classification\": {\n",
      "    \"format\": \"JSON\",\n",
      "    \"intent\": \"Invoice\"\n",
      "  },\n",
      "  \"result\": {\n",
      "    \"extracted_data\": {\n",
      "      \"invoice_id\": \"INV-2024-001\",\n",
      "      \"customer\": \"Tech Corp\",\n",
      "      \"amount\": 15000,\n",
      "      \"items\": [\n",
      "        \"Laptops\",\n",
      "        \"Monitors\",\n",
      "        \"Keyboards\"\n",
      "      ]\n",
      "    },\n",
      "    \"anomalies\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "=== PDF PROCESSING ===\n",
      "{\n",
      "  \"conversation_id\": \"830092628fb1\",\n",
      "  \"classification\": {\n",
      "    \"format\": \"PDF\",\n",
      "    \"intent\": \"Unknown\"\n",
      "  },\n",
      "  \"result\": {\n",
      "    \"sender\": \"Legal Team\",\n",
      "    \"intent\": \"Regulation\",\n",
      "    \"urgency\": \"High\",\n",
      "    \"topics\": [\n",
      "      \"Data Privacy\",\n",
      "      \"Regulation X.3.1\",\n",
      "      \"Compliance\"\n",
      "    ],\n",
      "    \"summary\": \"All departments must comply with Regulation X.3.1 by July 1, 2025, and submit a report by June 25.\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import hashlib\n",
    "import logging\n",
    "from datetime import datetime, timezone\n",
    "from typing import Any, Dict, Union\n",
    "import re\n",
    "import sqlite3\n",
    "from groq import Groq\n",
    "\n",
    "# ----------- CONFIGURATION ------------\n",
    "logging.basicConfig(\n",
    "    level=logging.WARNING,  # Reduced logging verbosity\n",
    "    format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\")\n",
    "if not GROQ_API_KEY:\n",
    "    logger.error(\"GROQ_API_KEY not set in environment variables.\")\n",
    "client = Groq(api_key=GROQ_API_KEY) if GROQ_API_KEY else None\n",
    "\n",
    "class SharedMemory:\n",
    "    def __init__(self, use_file_db=False):\n",
    "        if use_file_db:\n",
    "            self.conn = sqlite3.connect('shared_memory.db')\n",
    "        else:\n",
    "            self.conn = sqlite3.connect(':memory:')  # In-memory for clean runs\n",
    "        self._init_db()\n",
    "        \n",
    "    def _init_db(self):\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS conversation_logs (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                conversation_id TEXT NOT NULL,\n",
    "                timestamp TEXT NOT NULL,\n",
    "                data TEXT NOT NULL\n",
    "            )\n",
    "        ''')\n",
    "        self.conn.commit()\n",
    "        \n",
    "    def log(self, conversation_id: str, data: Dict[str, Any]) -> None:\n",
    "        entry = {\n",
    "            \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "            **data\n",
    "        }\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute('''\n",
    "            INSERT INTO conversation_logs (conversation_id, timestamp, data)\n",
    "            VALUES (?, ?, ?)\n",
    "        ''', (conversation_id, entry[\"timestamp\"], json.dumps(entry)))\n",
    "        self.conn.commit()\n",
    "\n",
    "    def get_context(self, conversation_id: str) -> list:\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute('''\n",
    "            SELECT data FROM conversation_logs \n",
    "            WHERE conversation_id = ?\n",
    "            ORDER BY timestamp ASC\n",
    "        ''', (conversation_id,))\n",
    "        return [json.loads(row[0]) for row in cursor.fetchall()]\n",
    "\n",
    "    def get_last_extraction(self, conversation_id: str) -> dict:\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute('''\n",
    "            SELECT data FROM conversation_logs \n",
    "            WHERE conversation_id = ? \n",
    "            AND data LIKE '%extracted_values%'\n",
    "            ORDER BY timestamp DESC\n",
    "            LIMIT 1\n",
    "        ''', (conversation_id,))\n",
    "        row = cursor.fetchone()\n",
    "        return json.loads(row[0])[\"extracted_values\"] if row else {}\n",
    "\n",
    "    def clear_conversation(self, conversation_id: str) -> None:\n",
    "        \"\"\"Clear specific conversation history\"\"\"\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute('DELETE FROM conversation_logs WHERE conversation_id = ?', (conversation_id,))\n",
    "        self.conn.commit()\n",
    "\n",
    "# Initialize shared memory\n",
    "shared_memory = SharedMemory()\n",
    "\n",
    "# ----------- GROQ COMPLETION UTILS ------------\n",
    "\n",
    "def groq_completion(\n",
    "    prompt: str,\n",
    "    system: str = \"\",\n",
    "    model: str = \"llama3-70b-8192\",\n",
    "    response_format: str = None,\n",
    "    max_retries: int = 3,\n",
    "    timeout: int = 30,\n",
    ") -> Any:\n",
    "    if client is None:\n",
    "        logger.error(\"Groq client not initialized.\")\n",
    "        raise RuntimeError(\"Groq client not available.\")\n",
    "\n",
    "    if response_format == \"json\" and \"json\" not in prompt.lower():\n",
    "        prompt += \"\\n\\nPlease respond in JSON format.\"\n",
    "\n",
    "    messages = ([{\"role\": \"system\", \"content\": system}] if system else []) + [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=0.3,\n",
    "                response_format={\"type\": \"json_object\"} if response_format == \"json\" else None,\n",
    "                timeout=timeout,\n",
    "            )\n",
    "            content = response.choices[0].message.content\n",
    "            return content\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Groq completion failed (attempt {attempt}): {e}\")\n",
    "            time.sleep(2 ** attempt)\n",
    "    logger.error(\"Groq completion failed after retries.\")\n",
    "    raise RuntimeError(\"Groq completion failed.\")\n",
    "\n",
    "# ----------- AGENTS ------------\n",
    "\n",
    "def classify_agent(input_data: Union[str, bytes]) -> dict:\n",
    "    \"\"\"Classifier Agent - Determines format and intent\"\"\"\n",
    "    # Check for PDF magic number\n",
    "    if isinstance(input_data, bytes) and input_data.startswith(b'%PDF'):\n",
    "        return {\"format\": \"PDF\", \"intent\": \"Unknown\"}\n",
    "    \n",
    "    # Convert bytes to string if needed\n",
    "    if isinstance(input_data, bytes):\n",
    "        try:\n",
    "            content = input_data.decode('utf-8')[:2000]\n",
    "        except UnicodeDecodeError:\n",
    "            content = str(input_data)[:2000]\n",
    "    else:\n",
    "        content = str(input_data)[:2000]\n",
    "\n",
    "    system_prompt = (\n",
    "        \"Classify input into format (PDF, JSON, Email) and intent \"\n",
    "        \"(Invoice, RFQ, Complaint, Regulation, Other). Output JSON with keys: 'format', 'intent'.\"\n",
    "    )\n",
    "    prompt = f\"Input:\\n{content}\\n\\nAnalysis:\"\n",
    "    try:\n",
    "        raw = groq_completion(prompt, system_prompt, response_format=\"json\")\n",
    "        result = json.loads(raw)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Classification error: {e}\")\n",
    "        return {\"format\": \"Email\", \"intent\": \"Other\"}\n",
    "\n",
    "def json_agent(payload: dict, conversation_id: str, intent: str) -> dict:\n",
    "    \"\"\"JSON Agent - Processes structured JSON data\"\"\"\n",
    "    context = shared_memory.get_last_extraction(conversation_id)\n",
    "    \n",
    "    system_prompt = (\n",
    "        \"You are a JSON processing expert. Extract data to match the target schema. \"\n",
    "        f\"Current intent: {intent}. Flag anomalies/errors in 'anomalies' array.\"\n",
    "    )\n",
    "    \n",
    "    prompt = (\n",
    "        f\"Previous Context: {json.dumps(context, indent=2)[:1000]}\\n\\n\"\n",
    "        f\"Target Schema:\\n- Fields vary based on intent: {intent}\\n\\n\"\n",
    "        f\"Input JSON Payload:\\n{json.dumps(payload, indent=2)[:3000]}\\n\\n\"\n",
    "        \"Output JSON with keys: 'extracted_data' and 'anomalies'.\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        raw = groq_completion(prompt, system_prompt, response_format=\"json\")\n",
    "        data = json.loads(raw)\n",
    "        \n",
    "        # Log agent activity\n",
    "        shared_memory.log(conversation_id, {\n",
    "            \"agent\": \"JSON_Agent\",\n",
    "            \"input_intent\": intent,\n",
    "            \"output\": data\n",
    "        })\n",
    "        \n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logger.error(f\"JSON agent error: {e}\")\n",
    "        return {\"extracted_data\": {}, \"anomalies\": [str(e)]}\n",
    "\n",
    "def email_agent(content: str, conversation_id: str, intent: str) -> dict:\n",
    "    \"\"\"Email Agent - Processes email/text content\"\"\"\n",
    "    # Clean and truncate email content\n",
    "    cleaned_content = re.sub(r'\\s+', ' ', content)[:5000]\n",
    "    context = shared_memory.get_last_extraction(conversation_id)\n",
    "    \n",
    "    system_prompt = (\n",
    "        \"You are an email processing expert. Extract key information. \"\n",
    "        f\"Current intent: {intent}. Output JSON with: sender, intent, urgency, topics, summary.\"\n",
    "    )\n",
    "    \n",
    "    prompt = (\n",
    "        f\"Previous Context: {json.dumps(context, indent=2)[:1000]}\\n\\n\"\n",
    "        f\"Email Content:\\n{cleaned_content}\\n\\n\"\n",
    "        \"Output JSON with keys: sender, intent, urgency, topics, summary.\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        raw = groq_completion(\n",
    "            prompt, \n",
    "            system_prompt, \n",
    "            model=\"llama3-70b-8192\",\n",
    "            response_format=\"json\"\n",
    "        )\n",
    "        data = json.loads(raw)\n",
    "        \n",
    "        # Log agent activity\n",
    "        shared_memory.log(conversation_id, {\n",
    "            \"agent\": \"Email_Agent\",\n",
    "            \"input_intent\": intent,\n",
    "            \"output\": data\n",
    "        })\n",
    "        \n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Email agent error: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def pdf_agent(pdf_bytes: bytes, conversation_id: str) -> dict:\n",
    "    \"\"\"PDF Agent - Extracts text from PDF and processes it\"\"\"\n",
    "    try:\n",
    "        from PyPDF2 import PdfReader\n",
    "        from io import BytesIO\n",
    "        \n",
    "        reader = PdfReader(BytesIO(pdf_bytes))\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text() or \"\"\n",
    "            text += page_text + \"\\n\"\n",
    "            if len(text) > 10000:  # Limit extraction\n",
    "                break\n",
    "        \n",
    "        # Classify content from text\n",
    "        classification = classify_agent(text[:2000])\n",
    "        intent = classification.get(\"intent\", \"Unknown\")\n",
    "        \n",
    "        # Route to email agent for content extraction\n",
    "        return email_agent(text, conversation_id, intent)\n",
    "        \n",
    "    except ImportError:\n",
    "        logger.error(\"PyPDF2 required for PDF processing\")\n",
    "        return {\"error\": \"PyPDF2 not installed\"}\n",
    "    except Exception as e:\n",
    "        logger.exception(\"PDF processing failed\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# ----------- MAIN ORCHESTRATOR ------------\n",
    "\n",
    "def process_input(input_data: Any, conversation_id: str = None, clear_memory: bool = False) -> dict:\n",
    "    \"\"\"Main orchestrator function\"\"\"\n",
    "    if not conversation_id:\n",
    "        conversation_id = hashlib.md5(str(time.time()).encode()).hexdigest()[:12]\n",
    "    \n",
    "    if clear_memory:\n",
    "        shared_memory.clear_conversation(conversation_id)\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Classify input\n",
    "        classification = classify_agent(input_data)\n",
    "        fmt = classification.get(\"format\", \"Email\")\n",
    "        intent = classification.get(\"intent\", \"Other\")\n",
    "        \n",
    "        # Step 2: Route to appropriate agent\n",
    "        if fmt == \"JSON\":\n",
    "            try:\n",
    "                payload = json.loads(input_data) if isinstance(input_data, str) else input_data\n",
    "            except (TypeError, json.JSONDecodeError):\n",
    "                payload = {\"raw_data\": str(input_data)[:1000]}\n",
    "            result = json_agent(payload, conversation_id, intent)\n",
    "        elif fmt == \"PDF\":\n",
    "            if not isinstance(input_data, bytes):\n",
    "                input_data = input_data.encode()\n",
    "            result = pdf_agent(input_data, conversation_id)\n",
    "        else:  # Email or fallback\n",
    "            content = input_data.decode() if isinstance(input_data, bytes) else str(input_data)\n",
    "            result = email_agent(content, conversation_id, intent)\n",
    "        \n",
    "        # Step 3: Log to shared memory\n",
    "        shared_memory.log(conversation_id, {\n",
    "            \"source\": \"user_input\",\n",
    "            \"type\": fmt,\n",
    "            \"intent\": intent,\n",
    "            \"extracted_values\": result\n",
    "        })\n",
    "        \n",
    "        # Return concise result\n",
    "        return {\n",
    "            \"conversation_id\": conversation_id,\n",
    "            \"classification\": classification,\n",
    "            \"result\": result\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Processing failed: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def get_conversation_history(conversation_id: str) -> list:\n",
    "    \"\"\"Get conversation history for a specific ID\"\"\"\n",
    "    return shared_memory.get_context(conversation_id)\n",
    "\n",
    "def print_result(result: dict, title: str = \"RESULT\"):\n",
    "    \"\"\"Pretty print results\"\"\"\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "    print()\n",
    "\n",
    "# ----------- EXAMPLE USAGE ------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example 1: Process Email\n",
    "    test_email = \"\"\"\n",
    "    From: customer@example.com\n",
    "    Subject: Product Complaint - Urgent\n",
    "\n",
    "    Dear Support Team,\n",
    "\n",
    "    I recently purchased a laptop from your store (order ID: 45321). \n",
    "    The screen started flickering within 3 days of use. This is unacceptable for a new product.\n",
    "\n",
    "    Please resolve this issue urgently.\n",
    "\n",
    "    Regards,\n",
    "    John Doe\n",
    "    \"\"\"\n",
    "    \n",
    "    result = process_input(test_email, clear_memory=True)\n",
    "    print_result(result, \"EMAIL PROCESSING\")\n",
    "    \n",
    "    # Example 2: Process JSON\n",
    "    test_json = {\n",
    "        \"invoice_id\": \"INV-2024-001\",\n",
    "        \"customer\": \"Tech Corp\",\n",
    "        \"amount\": 15000,\n",
    "        \"items\": [\"Laptops\", \"Monitors\", \"Keyboards\"]\n",
    "    }\n",
    "    \n",
    "    result = process_input(json.dumps(test_json), clear_memory=True)\n",
    "    print_result(result, \"JSON PROCESSING\")\n",
    "    \n",
    "    # Example 3: Process PDF (if files exist)\n",
    "    try:\n",
    "        with open(\"regulation.pdf\", \"rb\") as f:\n",
    "            pdf_bytes = f.read()\n",
    "        result = process_input(pdf_bytes, clear_memory=True)\n",
    "        print_result(result, \"PDF PROCESSING\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"=== PDF PROCESSING ===\")\n",
    "        print(\"No sample.pdf file found - skipping PDF test\")\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
